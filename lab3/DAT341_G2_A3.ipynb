{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85998053-d7ae-412d-838d-ae444d227b9c",
   "metadata": {},
   "source": [
    "# DAT341 Applied Machine Learning\n",
    "\n",
    "## Assginment 3: Stance classification\n",
    "\n",
    "### Part 1: Solve the Basic Problem\n",
    "\n",
    "First, let's import the datasets. There are two datasets which one of them is used for training and the other one is for testing. Meanwhile, we could print out part of the dataset to see the format of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd33faff-088c-43ac-a669-c9bf861f8ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sample\n",
      "     label                                               text\n",
      "0      0/0  A woman's autonomous right to decide for her o...\n",
      "1     1/-1   And yet ignorance is an enemy, even to its owner\n",
      "2      0/0  Anti vaxxer??? So if I have had a tetanus shot...\n",
      "3      0/0  Are you planning on getting the vaccine when i...\n",
      "4  0/0/0/0  Benefits outweigh the risks. Yes, the benefits...\n",
      "Test sample\n",
      "   label                                               text\n",
      "0      0  Extremely rare is only good if it doesn't happ...\n",
      "1      1  I have two parents in their 70s. Both had the ...\n",
      "2      0  Not getting vaccinated is still more dangerous...\n",
      "3      1  The average life expectancy of a human is 74 y...\n",
      "4      1  Trust the science is a dumb saying. Science is...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_file=\"a3_train_final.tsv\"\n",
    "test_file=\"a3_test.tsv\"\n",
    "\n",
    "df_train=pd.read_csv(train_file,sep=\"\\t\",header=None,names=[\"label\",\"text\"])\n",
    "df_test=pd.read_csv(test_file,sep=\"\\t\",header=None,names=[\"label\",\"text\"] )\n",
    "\n",
    "print(\"Train sample\")\n",
    "print(df_train.head())\n",
    "print(\"Test sample\")\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f5fb25-abad-43d6-b0bf-932667341e45",
   "metadata": {},
   "source": [
    "Before we preprocess the data, we first need to handle the multi-annotation problem. Different people(2 or more) could give different remark to the same comment. To simplify the situation, we could take the average of multiple annotation values and rounding to the nearest integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be3d4fcf-9c73-45d6-acb0-142666294e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    5889\n",
      "1    5707\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def resolve_labels(label_str):\n",
    "    labels = list(map(int, label_str.split('/')))  \n",
    "    labels = [0.5 if l == -1 else l for l in labels]  \n",
    "    return round(np.mean(labels))  \n",
    "\n",
    "df_train[\"label\"] = df_train[\"label\"].astype(str).apply(resolve_labels)\n",
    "df_train = df_train.dropna(subset=[\"label\"]).reset_index(drop=True)\n",
    "\n",
    "print(df_train[\"label\"].value_counts()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134defed-41a2-4ce5-b33c-0848ae8eba64",
   "metadata": {},
   "source": [
    "It seems like the nubmer of the annoation in '0' is similar to that in '1'. Thus, we could move on to the next part which we handle the text of the comments here. As is shown in the dataset and the common sense about remarks in Youtube or other platforms, there might be complex symbols and useless words in the comments. The text needs to be cleaned by removing punctuation, converting to lowercase, removing stopwords, eliminating extra spaces, and applying stemming or lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8ddbdc7-7d41-4a7f-92fb-3ead49e6aa75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed Text Sample:\n",
      "   label                                               text  \\\n",
      "0      0  A woman's autonomous right to decide for her o...   \n",
      "1      1   And yet ignorance is an enemy, even to its owner   \n",
      "2      0  Anti vaxxer??? So if I have had a tetanus shot...   \n",
      "3      0  Are you planning on getting the vaccine when i...   \n",
      "4      0  Benefits outweigh the risks. Yes, the benefits...   \n",
      "\n",
      "                                          clean_text  \n",
      "0  womans autonomous right decide body dont auton...  \n",
      "1                     yet ignorance enemy even owner  \n",
      "2  anti vaxxer tetanus shot typhoid fever hepatit...  \n",
      "3  planning getting vaccine available nope hopefu...  \n",
      "4  benefits outweigh risks yes benefits getting s...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\xiach\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  \n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  \n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words] \n",
    "    return \" \".join(words)\n",
    "\n",
    "df_train[\"clean_text\"] = df_train[\"text\"].apply(preprocess_text)\n",
    "df_test[\"clean_text\"] = df_test[\"text\"].apply(preprocess_text)\n",
    "\n",
    "print(\"\\nProcessed Text Sample:\")\n",
    "print(df_train.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354d4752-b8f8-40ea-bb42-a22efb932442",
   "metadata": {},
   "source": [
    "Performing TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3037d0df-d0ed-4756-b5ed-c0506a22b921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completed!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "X_train = vectorizer.fit_transform(df_train[\"clean_text\"])\n",
    "y_train = df_train[\"label\"]\n",
    "\n",
    "X_test = vectorizer.transform(df_test[\"clean_text\"])\n",
    "y_test = df_test[\"label\"]\n",
    "\n",
    "print(\"\\nCompleted!!!!!!!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a584c21-1d46-4e9c-8a25-4c0d35741cac",
   "metadata": {},
   "source": [
    "Logistic Regression and Support Vector Machine\n",
    "\n",
    "In this task, we choose Logistic Regression and Support Vector Machine as classification models because they are well-suited for high-dimensional sparse data. Logistic Regression is an efficient linear classifier with low computational cost, making it ideal for binary classification tasks while offering good interpretability. SVM performs well in high-dimensional spaces by finding the optimal decision boundary, improving generalization, especially for small datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "952471fe-a541-4d71-bcac-0b5fe11ce237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "svm_model = SVC(kernel=\"linear\")\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f74044-4f4d-43c4-8f77-03682fa00162",
   "metadata": {},
   "source": [
    "Print out the report of these two model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfaf86c9-d0a2-401a-bb2d-54953041d313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.86      0.82       267\n",
      "           1       0.85      0.77      0.81       267\n",
      "\n",
      "    accuracy                           0.81       534\n",
      "   macro avg       0.82      0.81      0.81       534\n",
      "weighted avg       0.82      0.81      0.81       534\n",
      "\n",
      "\n",
      "SVM Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       267\n",
      "           1       0.85      0.79      0.82       267\n",
      "\n",
      "    accuracy                           0.83       534\n",
      "   macro avg       0.83      0.83      0.83       534\n",
      "weighted avg       0.83      0.83      0.83       534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLogistic Regression Performance:\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "print(\"\\nSVM Performance:\")\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785bae7b-ff0b-404f-b6a5-f0acf5e53ee4",
   "metadata": {},
   "source": [
    "According to the results, it turns out that SVM has a better performance. Thus, we could choose SVM to be our model.\n",
    "\n",
    "### Part 2: Try out the powerful modern text representation model -- BERT.\n",
    "\n",
    "First import libiraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65e1af8e-d728-4b33-af90-23a0da70c0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e462c74-ec67-41dc-92d3-e81c4030c259",
   "metadata": {},
   "source": [
    "Import the dataset and handle the data like we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbe6d14e-1a96-4a94-a0ef-ce3db0703f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "label\n",
      "0    5889\n",
      "1    5707\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "train_file = \"a3_train_final.tsv\"\n",
    "test_file = \"a3_test.tsv\"\n",
    "\n",
    "df_train = pd.read_csv(train_file, sep=\"\\t\", header=None, names=[\"label\", \"text\"])\n",
    "df_test = pd.read_csv(test_file, sep=\"\\t\", header=None, names=[\"label\", \"text\"])\n",
    "\n",
    "def resolve_labels(label_str):\n",
    "    labels = list(map(int, label_str.split('/')))\n",
    "    labels = [l for l in labels if l != -1]  \n",
    "    return round(np.mean(labels)) if labels else None  \n",
    "\n",
    "df_train[\"label\"] = df_train[\"label\"].astype(str).apply(resolve_labels)\n",
    "df_train = df_train.dropna()  \n",
    "df_test[\"label\"] = df_test[\"label\"].astype(int)\n",
    "\n",
    "print(df_train[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff5ebbb-c999-4461-9cc4-6ac46b5e8987",
   "metadata": {},
   "source": [
    "Initialize the BERT classifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80343eac-e395-4519-8934-8563c49ec6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "class VaccineDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = int(self.labels[idx])  \n",
    "        encoding = self.tokenizer(text, padding=\"max_length\", truncation=True, max_length=self.max_len, return_tensors=\"pt\")\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"label\": torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "train_dataset = VaccineDataset(df_train[\"text\"].tolist(), df_train[\"label\"].tolist(), tokenizer)\n",
    "test_dataset = VaccineDataset(df_test[\"text\"].tolist(), df_test[\"label\"].tolist(), tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True) \n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "num_training_steps = len(train_loader) * 3  \n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step() \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader)}\")\n",
    "    torch.cuda.empty_cache()  \n",
    "\n",
    "model.save_pretrained(\"bert_vaccine_classifier\")\n",
    "tokenizer.save_pretrained(\"bert_vaccine_classifier\")\n",
    "\n",
    "print(\"Complete!!!!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77200ea-3162-4eb7-be2e-e11824e2544e",
   "metadata": {},
   "source": [
    "Next stage, let's evaluate the model by the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3e1c9f-ef79-4962-8974-d285b2afbaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    predictions, true_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "\n",
    "            predictions.extend(preds)\n",
    "            true_labels.extend(labels)\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(true_labels, predictions))\n",
    "    print(f\"Accuracy: {accuracy_score(true_labels, predictions):.4f}\")\n",
    "\n",
    "evaluate_model(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
